{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Instalación de bibliotecas\n",
        "!pip install tensorflow pandas matplotlib opencv-python scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30i74QiG1K7s",
        "outputId": "662d6316-889b-4156-d152-1ba04a646cd0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWU883Bg1FTX",
        "outputId": "f1075d57-52ac-470d-838f-f4f458b944b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/root/.kaggle\"\n",
        "!mkdir -p /root/.kaggle\n",
        "!mv kaggle.json /root/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d msambare/fer2013\n",
        "!kaggle datasets download -d tapakah68/facial-emotion-recognition\n",
        "!kaggle datasets download -d dilkushsingh/facial-emotion-dataset\n",
        "!kaggle datasets download -d samaneheslamifar/facial-emotion-expressions\n",
        "!kaggle datasets download -d missaouimohamedamine/face-emotion-dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-jAIsiC1d0g",
        "outputId": "f8a549ae-c5fe-45f6-e00b-31109050f5a6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/msambare/fer2013\n",
            "License(s): DbCL-1.0\n",
            "Downloading fer2013.zip to /content\n",
            " 80% 48.0M/60.3M [00:00<00:00, 267MB/s]\n",
            "100% 60.3M/60.3M [00:00<00:00, 246MB/s]\n",
            "Dataset URL: https://www.kaggle.com/datasets/tapakah68/facial-emotion-recognition\n",
            "License(s): Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)\n",
            "Downloading facial-emotion-recognition.zip to /content\n",
            " 97% 421M/433M [00:01<00:00, 277MB/s]\n",
            "100% 433M/433M [00:01<00:00, 253MB/s]\n",
            "Dataset URL: https://www.kaggle.com/datasets/dilkushsingh/facial-emotion-dataset\n",
            "License(s): Attribution 4.0 International (CC BY 4.0)\n",
            "Downloading facial-emotion-dataset.zip to /content\n",
            " 68% 41.0M/60.7M [00:00<00:00, 236MB/s] \n",
            "100% 60.7M/60.7M [00:00<00:00, 252MB/s]\n",
            "Dataset URL: https://www.kaggle.com/datasets/samaneheslamifar/facial-emotion-expressions\n",
            "License(s): unknown\n",
            "Downloading facial-emotion-expressions.zip to /content\n",
            " 97% 117M/121M [00:00<00:00, 256MB/s] \n",
            "100% 121M/121M [00:00<00:00, 252MB/s]\n",
            "Dataset URL: https://www.kaggle.com/datasets/missaouimohamedamine/face-emotion-dataset\n",
            "License(s): apache-2.0\n",
            "Downloading face-emotion-dataset.zip to /content\n",
            " 76% 93.0M/123M [00:00<00:00, 202MB/s]\n",
            "100% 123M/123M [00:00<00:00, 201MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Descomprimimos los archivos\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "download_dir = '/content/'\n",
        "\n",
        "zip_files = [f for f in os.listdir(download_dir) if f.endswith('.zip')]\n",
        "\n",
        "for zip_file in zip_files:\n",
        "    zip_path = os.path.join(download_dir, zip_file)\n",
        "    extract_dir = os.path.join(download_dir, zip_file.replace('.zip', ''))\n",
        "    os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)  # Extraer todos los archivos\n",
        "    print(f\"Descomprimido: {zip_file} en {extract_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPqcQJ4s1inK",
        "outputId": "3159e6e3-fc7a-4817-c0d1-f8f19317b457"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descomprimido: facial-emotion-expressions.zip en /content/facial-emotion-expressions\n",
            "Descomprimido: facial-emotion-dataset.zip en /content/facial-emotion-dataset\n",
            "Descomprimido: face-emotion-dataset.zip en /content/face-emotion-dataset\n",
            "Descomprimido: fer2013.zip en /content/fer2013\n",
            "Descomprimido: facial-emotion-recognition.zip en /content/facial-emotion-recognition\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapeo de las etiquetas a las nuevas categorías numeradas\n",
        "label_mapping = {\n",
        "    'angry': 0,       # angry -> 0\n",
        "    'neutral': 1,      # neutral -> 1\n",
        "    'disgust': 2,      # disgust -> 2\n",
        "    'fear': 3,         # fear -> 3\n",
        "    'happy': 4,        # happy -> 4\n",
        "    'sad': 5,      # sad -> 5\n",
        "    'surprise': 6,     # surprise -> 6\n",
        "}"
      ],
      "metadata": {
        "id": "S-Befbhl1k5s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Función para cargar imágenes\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Función para cargar imágenes y etiquetarlas\n",
        "def load_images_and_labels(dataset_path, label_mapping):\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "\n",
        "    # Recorrer las carpetas dentro del dataset\n",
        "    for class_folder in os.listdir(dataset_path):\n",
        "        class_path = os.path.join(dataset_path, class_folder)\n",
        "\n",
        "        # Asegurarse de que es una carpeta (no un archivo)\n",
        "        if os.path.isdir(class_path):\n",
        "            # Normalizar el nombre de la carpeta a minúsculas\n",
        "            normalized_class_folder = class_folder.lower()\n",
        "\n",
        "            # Si la carpeta pertenece a alguna de las categorías con nombre variable\n",
        "            if normalized_class_folder in ['angry', 'anger']:\n",
        "                mapped_label = label_mapping['angry']\n",
        "            elif normalized_class_folder in ['sad', 'sadness']:\n",
        "                mapped_label = label_mapping['sad']\n",
        "            elif normalized_class_folder in label_mapping:\n",
        "                mapped_label = label_mapping[normalized_class_folder]\n",
        "            else:\n",
        "                print(f\"Etiqueta no mapeada: {class_folder}\")\n",
        "                continue  # Si no se encuentra en el mapeo, se omite\n",
        "\n",
        "            for img_name in os.listdir(class_path):\n",
        "                img_path = os.path.join(class_path, img_name)\n",
        "                image_paths.append(img_path)\n",
        "                labels.append(mapped_label)\n",
        "\n",
        "    # Crear un DataFrame con las rutas de imágenes y las etiquetas mapeadas\n",
        "    df = pd.DataFrame({'image_path': image_paths, 'label': labels})\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "_qhsEpYq1pBw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Esto se hace para el dataset que no tiene la misma estructura que los otros\n",
        "#Dataset facial-emotion-recognition\n",
        "# Diccionario de correcciones para los nombres de las imágenes\n",
        "corrections = {\n",
        "    'surprised': 'surprise',  # 'surprised' -> 'surprise'\n",
        "    'anger': 'angry'          # 'anger' -> 'angry'\n",
        "}\n",
        "\n",
        "# Función para cargar imágenes y etiquetarlas\n",
        "def load_images_and_labels_2(dataset_path, label_mapping, corrections):\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "\n",
        "    # Recorrer las carpetas dentro del dataset (cada carpeta es un sujeto)\n",
        "    for subject_folder in os.listdir(dataset_path):\n",
        "        subject_path = os.path.join(dataset_path, subject_folder)\n",
        "\n",
        "        # Asegurarse de que es una carpeta (no un archivo)\n",
        "        if os.path.isdir(subject_path):\n",
        "            for img_name in os.listdir(subject_path):\n",
        "                img_path = os.path.join(subject_path, img_name)\n",
        "\n",
        "                # Usar el nombre de la imagen sin la extensión y convertirlo a minúsculas\n",
        "                img_name_lower = img_name.lower().split('.')[0]\n",
        "\n",
        "                # Corregir el nombre si tiene alguna de las variaciones que deben ser mapeadas\n",
        "                if img_name_lower in corrections:\n",
        "                    img_name_lower = corrections[img_name_lower]\n",
        "\n",
        "                # Buscar el mapeo para la etiqueta\n",
        "                mapped_label = label_mapping.get(img_name_lower, None)\n",
        "                if mapped_label is None:\n",
        "                    print(f\"Etiqueta no mapeada: {img_name_lower} en la carpeta {subject_folder}\")\n",
        "                    continue  # Si la etiqueta no está mapeada, la imagen se omite\n",
        "\n",
        "                image_paths.append(img_path)\n",
        "                labels.append(mapped_label)\n",
        "\n",
        "    # Crear un DataFrame con las rutas de imágenes y las etiquetas mapeadas\n",
        "    df = pd.DataFrame({'image_path': image_paths, 'label': labels})\n",
        "    return df\n",
        "\n"
      ],
      "metadata": {
        "id": "q7lh8DZj1zZD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos dataframes con las etiquetas y rutas de cada dataset y leugo los unimos\n",
        "dataset_paths = [\n",
        "    '/content/fer2013/test',\n",
        "    '/content/fer2013/train',\n",
        "    '/content/facial-emotion-dataset/test_dir',\n",
        "    '/content/facial-emotion-dataset/train_dir',\n",
        "    '/content/face-emotion-dataset/test',\n",
        "    '/content/face-emotion-dataset/train',\n",
        "    '/content/facial-emotion-expressions/images/images/train',\n",
        "    '/content/facial-emotion-expressions/images/images/validation'\n",
        "\n",
        "]\n",
        "\n",
        "dfs = []\n",
        "for path in dataset_paths:\n",
        "    if path == '/content/facial-emotion-recognition/images':\n",
        "        df = load_images_and_labels_2(path, label_mapping, corrections)\n",
        "    else:\n",
        "        df = load_images_and_labels(path, label_mapping)\n",
        "    dfs.append(df)\n",
        "\n",
        "# Unir todos los DataFrames\n",
        "df_combined = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Verificar la distribución de las etiquetas\n",
        "print(df_combined.head())\n",
        "print(df_combined['label'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xgdlBAJ13g4",
        "outputId": "8e71ecc2-9610-4849-db06-17e4e5706500"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          image_path  label\n",
            "0  /content/fer2013/test/neutral/PublicTest_69204...      1\n",
            "1  /content/fer2013/test/neutral/PublicTest_93950...      1\n",
            "2  /content/fer2013/test/neutral/PrivateTest_9908...      1\n",
            "3  /content/fer2013/test/neutral/PrivateTest_9183...      1\n",
            "4  /content/fer2013/test/neutral/PrivateTest_2283...      1\n",
            "label\n",
            "4    43950\n",
            "1    31087\n",
            "5    30507\n",
            "3    25049\n",
            "0    24663\n",
            "6    19970\n",
            "2     7849\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar si las rutas de las imágenes son correctas\n",
        "for index, row in df_combined.iterrows():\n",
        "    if not os.path.exists(row['image_path']):\n",
        "        print(f\"¡Ruta no válida! {row['image_path']}\")\n"
      ],
      "metadata": {
        "id": "POZP2x8V17ML"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Obtener los conteos de las categorías\n",
        "conteo_labels = df_combined['label'].value_counts()\n",
        "\n",
        "# Ordenar las categorías (de 0 a 6 en este caso)\n",
        "orden_categorias = list(range(7))  # Crea la lista de categorías en el orden deseado\n",
        "conteo_labels = conteo_labels.reindex(orden_categorias, fill_value=0)  # Reorganiza y rellena con 0 si faltan categorías\n",
        "\n",
        "\n",
        "# Gráfica usando seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x=conteo_labels.index, y=conteo_labels.values, palette='viridis', order=orden_categorias)\n",
        "plt.title('Cantidad de datos por categoría', fontsize=16)\n",
        "plt.xlabel('Categoría', fontsize=12)\n",
        "plt.ylabel('Cantidad', fontsize=12)\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "3g6RyG-12Agu",
        "outputId": "686874b2-8ff6-4f42-e2fa-d8f82ea0faac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-704aff9677a4>:14: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=conteo_labels.index, y=conteo_labels.values, palette='viridis', order=orden_categorias)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imgaug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLsWlCni2VWT",
        "outputId": "1406ee79-8807-4769-a3f8-4f2fca7d261a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting imgaug\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug) (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from imgaug) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imgaug) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from imgaug) (11.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug) (3.8.0)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.10/dist-packages (from imgaug) (0.24.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from imgaug) (4.10.0.84)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug) (2.36.1)\n",
            "Collecting Shapely (from imgaug)\n",
            "  Downloading shapely-2.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug) (3.4.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug) (0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (2.9.0.post0)\n",
            "Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.0/948.0 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shapely-2.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Shapely, imgaug\n",
            "Successfully installed Shapely-2.0.6 imgaug-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imgaug import augmenters as iaa\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def load_and_preprocess_images(df, img_size=(48, 48), augment=False):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    # Configurar augmenters\n",
        "    aug = iaa.Sequential([\n",
        "        iaa.Affine(rotate=(-15, 15)),\n",
        "        iaa.Fliplr(0.5),\n",
        "        iaa.Multiply((0.8, 1.2)),\n",
        "    ]) if augment else None\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        if not os.path.exists(row['image_path']):\n",
        "            print(f\"Imagen no encontrada: {row['image_path']}\")\n",
        "            continue\n",
        "\n",
        "        # Leer la imagen\n",
        "        img = cv2.imread(row['image_path'])\n",
        "        if img is None:\n",
        "            print(f\"Error al cargar la imagen: {row['image_path']}\")\n",
        "            continue\n",
        "\n",
        "        # Convertir a escala de grises y redimensionar\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        img = cv2.resize(img, img_size)\n",
        "\n",
        "        # Asegurarse de que la imagen está en formato uint8\n",
        "        img = img.astype(np.uint8)\n",
        "\n",
        "        # Aplicar data augmentation (si está habilitado)\n",
        "        if augment:\n",
        "            img = aug.augment_image(img)\n",
        "\n",
        "        # Normalizar la imagen (convertir a float después de augmentación)\n",
        "        img = img / 255.0\n",
        "\n",
        "        images.append(img)\n",
        "        labels.append(row['label'])\n",
        "\n",
        "    # Convertir a numpy arrays\n",
        "    images = np.array(images).reshape(-1, img_size[0], img_size[1], 1)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "Zak1qjL_2Cgn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Configura las transformaciones\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Filtra las imágenes de la clase 2\n",
        "df_class_2 = df_combined[df_combined['label'] == 2]\n",
        "\n",
        "# Directorio de salida para las imágenes aumentadas\n",
        "output_dir = \"augmented_class_2\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Tamaño de las imágenes (ajustar si es diferente)\n",
        "img_size = (48, 48)\n",
        "\n",
        "# Número de imágenes aumentadas por ejemplo original\n",
        "n_augmentations = 5\n",
        "\n",
        "for index, row in df_class_2.iterrows():\n",
        "    img_path = row['image_path']\n",
        "\n",
        "    # Cargar la imagen original\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        print(f\"Error al cargar la imagen: {img_path}\")\n",
        "        continue\n",
        "\n",
        "    # Redimensionar si es necesario\n",
        "    img = cv2.resize(img, img_size)\n",
        "\n",
        "    # Expandir dimensión para adaptarse a ImageDataGenerator\n",
        "    img = np.expand_dims(img, axis=-1)\n",
        "    img = np.expand_dims(img, axis=0)  # (1, img_size[0], img_size[1], 1)\n",
        "\n",
        "    # Generar imágenes aumentadas\n",
        "    i = 0\n",
        "    for batch in datagen.flow(img, batch_size=1, save_to_dir=output_dir,\n",
        "                              save_prefix='class_3', save_format='png'):\n",
        "        i += 1\n",
        "        if i >= n_augmentations:\n",
        "            break  # Limitar el número de augmentaciones por imagen\n",
        "\n",
        "print(f\"Datos aumentados guardados en: {output_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1OtoLNx2azx",
        "outputId": "05c50f17-53e9-4d9f-d921-d2b6b867df89"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos aumentados guardados en: augmented_class_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "# Obtener los nuevos paths de las imágenes aumentadas\n",
        "augmented_images = glob.glob(os.path.join(output_dir, \"*.png\"))\n",
        "\n",
        "# Crear un nuevo dataframe para las imágenes aumentadas\n",
        "df_augmented = pd.DataFrame({\n",
        "    'image_path': augmented_images,\n",
        "    'label': 2  # Etiqueta correspondiente\n",
        "})\n",
        "\n",
        "# Concatenar con el dataset original\n",
        "df_new = pd.concat([df_combined, df_augmented], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "K4wM4VdV2fPT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar la distribución de las etiquetas\n",
        "print(df_new['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnNCYQ8F2rjc",
        "outputId": "4b741aa8-c635-4ce4-c7bb-1eef73bd61f8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "4    43950\n",
            "1    31087\n",
            "5    30507\n",
            "3    25049\n",
            "0    24663\n",
            "6    19970\n",
            "2    17659\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# Crear un DataFrame para cada clase\n",
        "dfs = [df_new[df_new['label'] == label] for label in df_new['label'].unique()]\n",
        "\n",
        "# Igualar al tamaño de la clase más pequeña\n",
        "min_size = min(len(df) for df in dfs)\n",
        "dfs_resampled = [resample(df, replace=False, n_samples=min_size, random_state=42) for df in dfs]\n",
        "\n",
        "# Reunir las clases balanceadas\n",
        "df_balanced = pd.concat(dfs_resampled)\n",
        "\n",
        "# Verificar las nuevas distribuciones\n",
        "print(df_balanced['label'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53193Oxl2xxK",
        "outputId": "dd451c44-4ea3-4d76-ac26-d079e089ebcb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "1    17659\n",
            "0    17659\n",
            "3    17659\n",
            "6    17659\n",
            "5    17659\n",
            "4    17659\n",
            "2    17659\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir en entrenamiento (60%), validación (20%) y prueba (20%)\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_and_preprocess_images(df, img_size=(48, 48)):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        # Verificar si la imagen existe\n",
        "        if not os.path.exists(row['image_path']):\n",
        "            print(f\"Imagen no encontrada: {row['image_path']}\")\n",
        "            continue  # Salta a la siguiente imagen\n",
        "\n",
        "        # Cargar la imagen\n",
        "        img = cv2.imread(row['image_path'])\n",
        "\n",
        "        if img is None:\n",
        "            print(f\"Error al cargar la imagen: {row['image_path']}\")\n",
        "            continue  # Salta a la siguiente imagen\n",
        "\n",
        "        # Convertir la imagen a escala de grises\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Redimensionar la imagen\n",
        "        img = cv2.resize(img, img_size)\n",
        "\n",
        "        # Normalizar la imagen\n",
        "        img = img / 255.0\n",
        "\n",
        "        images.append(img)\n",
        "        labels.append(row['label'])\n",
        "\n",
        "    # Convertir a arrays de numpy\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # Para la compatibilidad con CNN\n",
        "    images = images.reshape(-1, img_size[0], img_size[1], 1)  # Para imágenes en escala de grises\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "# Cargar y preprocesar las imágenes y etiquetas\n",
        "images, labels = load_and_preprocess_images(df_balanced)\n",
        "\n",
        "# Dividir en entrenamiento (60%), validación (20%) y prueba (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Entrenamiento: {len(X_train)} muestras\")\n",
        "print(f\"Validación: {len(X_val)} muestras\")\n",
        "print(f\"Prueba: {len(X_test)} muestras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLlTfe-A2zUk",
        "outputId": "114e3658-e1db-4b7e-f52d-ee88de1afee9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenamiento: 74167 muestras\n",
            "Validación: 24723 muestras\n",
            "Prueba: 24723 muestras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Parámetros del modelo\n",
        "input_shape = (48, 48, 1)  # Cambia según las dimensiones de tus imágenes\n",
        "num_classes = 7\n",
        "\n",
        "# Definición del modelo\n",
        "model = Sequential([\n",
        "    # Capa 1: Convolución + BatchNormalization + ReLU + MaxPooling\n",
        "    Conv2D(32, (3, 3), padding='same', input_shape=input_shape),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Capa 2: Convolución + BatchNormalization + ReLU + MaxPooling\n",
        "    Conv2D(64, (3, 3), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Capa 3: Convolución + BatchNormalization + ReLU + MaxPooling\n",
        "    Conv2D(128, (3, 3), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Capa 4: Convolución adicional + BatchNormalization + ReLU + MaxPooling\n",
        "    Conv2D(256, (3, 3), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Capa 5: Convolución adicional + BatchNormalization + ReLU + MaxPooling\n",
        "    Conv2D(512, (3, 3), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Capa de aplanamiento\n",
        "    Flatten(),\n",
        "\n",
        "    # Capa completamente conectada\n",
        "    Dense(512),\n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    Dropout(0.5),  # Regularización\n",
        "\n",
        "    # Capa de salida\n",
        "    Dense(num_classes, activation='softmax')  # Softmax para clasificación\n",
        "])\n",
        "\n",
        "# Compilación del modelo\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Resumen del modelo\n",
        "model.summary()\n",
        "\n",
        "# Definición del EarlyStopping\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',        # Métrica a monitorear (puede ser 'val_loss' o 'val_accuracy')\n",
        "    patience=3,                # Número de épocas sin mejora antes de detenerse\n",
        "    restore_best_weights=True  # Restaura los pesos del modelo cuando se alcanza el mejor rendimiento\n",
        ")\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=10,  # Número de épocas ajustable\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping]  # Añade el callback de EarlyStopping\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOZCjv2D287L",
        "outputId": "4a7fc417-31da-4029-eb64-5e078bde0fce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_15 (Conv2D)          (None, 48, 48, 32)        320       \n",
            "                                                                 \n",
            " batch_normalization_18 (Ba  (None, 48, 48, 32)        128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_18 (Activation)  (None, 48, 48, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPooli  (None, 24, 24, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 24, 24, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_19 (Ba  (None, 24, 24, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_19 (Activation)  (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPooli  (None, 12, 12, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 12, 12, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_20 (Ba  (None, 12, 12, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_20 (Activation)  (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPooli  (None, 6, 6, 128)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 6, 6, 256)         295168    \n",
            "                                                                 \n",
            " batch_normalization_21 (Ba  (None, 6, 6, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_21 (Activation)  (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPooli  (None, 3, 3, 256)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 3, 3, 512)         1180160   \n",
            "                                                                 \n",
            " batch_normalization_22 (Ba  (None, 3, 3, 512)         2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_22 (Activation)  (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPooli  (None, 1, 1, 512)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " batch_normalization_23 (Ba  (None, 512)               2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_23 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 7)                 3591      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1840263 (7.02 MB)\n",
            "Trainable params: 1837255 (7.01 MB)\n",
            "Non-trainable params: 3008 (11.75 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "2318/2318 [==============================] - 1025s 441ms/step - loss: 1.3447 - accuracy: 0.5037 - val_loss: 1.7345 - val_accuracy: 0.4290\n",
            "Epoch 2/10\n",
            "2318/2318 [==============================] - 1021s 441ms/step - loss: 0.9378 - accuracy: 0.6557 - val_loss: 1.0457 - val_accuracy: 0.6204\n",
            "Epoch 3/10\n",
            "2318/2318 [==============================] - 1018s 439ms/step - loss: 0.6964 - accuracy: 0.7535 - val_loss: 0.9675 - val_accuracy: 0.6839\n",
            "Epoch 4/10\n",
            "2318/2318 [==============================] - 1020s 440ms/step - loss: 0.4882 - accuracy: 0.8330 - val_loss: 1.6448 - val_accuracy: 0.5990\n",
            "Epoch 5/10\n",
            "2318/2318 [==============================] - 1023s 442ms/step - loss: 0.3524 - accuracy: 0.8833 - val_loss: 0.8265 - val_accuracy: 0.7339\n",
            "Epoch 6/10\n",
            "2318/2318 [==============================] - 1027s 443ms/step - loss: 0.2699 - accuracy: 0.9134 - val_loss: 0.5983 - val_accuracy: 0.8331\n",
            "Epoch 7/10\n",
            "2318/2318 [==============================] - 1019s 440ms/step - loss: 0.2223 - accuracy: 0.9301 - val_loss: 0.5067 - val_accuracy: 0.8655\n",
            "Epoch 8/10\n",
            "2318/2318 [==============================] - 1021s 441ms/step - loss: 0.1906 - accuracy: 0.9408 - val_loss: 0.9474 - val_accuracy: 0.7792\n",
            "Epoch 9/10\n",
            " 493/2318 [=====>........................] - ETA: 12:22 - loss: 0.1342 - accuracy: 0.9584"
          ]
        }
      ]
    }
  ]
}