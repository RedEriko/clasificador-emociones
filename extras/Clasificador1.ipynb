{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTql6lj1lAiD",
        "outputId": "29b505e3-3304-45c4-abb6-8612aa156961"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "mv: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# Instalación de bibliotecas\n",
        "!pip install tensorflow pandas matplotlib opencv-python scikit-learn\n",
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.layers import LeakyReLU, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/root/.kaggle\"\n",
        "!mkdir -p /root/.kaggle\n",
        "!mv kaggle.json /root/.kaggle/\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw-2kUeKmyw8",
        "outputId": "a675a3e8-ca96-4e57-d82c-5ae2294fc005"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/msambare/fer2013\n",
            "License(s): DbCL-1.0\n",
            "Downloading fer2013.zip to /content\n",
            " 75% 45.0M/60.3M [00:00<00:00, 98.4MB/s]\n",
            "100% 60.3M/60.3M [00:00<00:00, 114MB/s] \n",
            "403 - Forbidden - Permission 'datasets.get' was denied\n",
            "Dataset URL: https://www.kaggle.com/datasets/ananthu017/emotion-detection-fer\n",
            "License(s): CC0-1.0\n",
            "Downloading emotion-detection-fer.zip to /content\n",
            " 89% 58.0M/65.2M [00:00<00:00, 76.7MB/s]\n",
            "100% 65.2M/65.2M [00:01<00:00, 67.6MB/s]\n",
            "403 - Forbidden - Permission 'datasets.get' was denied\n",
            "Dataset URL: https://www.kaggle.com/datasets/missaouimohamedamine/face-emotion-dataset\n",
            "License(s): apache-2.0\n",
            "Downloading face-emotion-dataset.zip to /content\n",
            "100% 123M/123M [00:02<00:00, 77.1MB/s]\n",
            "100% 123M/123M [00:02<00:00, 60.1MB/s]\n",
            "Dataset URL: https://www.kaggle.com/datasets/tonny22/dataset-of-faces-as-per-emotions\n",
            "License(s): unknown\n",
            "Downloading dataset-of-faces-as-per-emotions.zip to /content\n",
            "100% 462M/464M [00:07<00:00, 81.2MB/s]\n",
            "100% 464M/464M [00:07<00:00, 67.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d msambare/fer2013\n",
        "!kaggle datasets download -d tapakah68/facial-emotion-recognitio\n",
        "!kaggle datasets download -d ananthu017/emotion-detection-fer\n",
        "!kaggle datasets download -d samaneheslamifar/facial-emotion-expression\n",
        "!kaggle datasets download -d missaouimohamedamine/face-emotion-dataset\n",
        "!kaggle datasets download -d tonny22/dataset-of-faces-as-per-emotions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwsIybjlnuZi",
        "outputId": "88adb6c4-2682-4ec9-fb00-d97b46c6ef1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Descomprimido: emotion-detection-fer.zip en /content/emotion-detection-fer\n",
            "Descomprimido: fer2013.zip en /content/fer2013\n",
            "Descomprimido: dataset-of-faces-as-per-emotions.zip en /content/dataset-of-faces-as-per-emotions\n",
            "Descomprimido: face-emotion-dataset.zip en /content/face-emotion-dataset\n"
          ]
        }
      ],
      "source": [
        "# Directorio donde están los archivos .zip descargados\n",
        "download_dir = '/content/'\n",
        "\n",
        "# Listamos todos los archivos en el directorio\n",
        "zip_files = [f for f in os.listdir(download_dir) if f.endswith('.zip')]\n",
        "\n",
        "# Descomprimir todos los archivos .zip\n",
        "for zip_file in zip_files:\n",
        "    zip_path = os.path.join(download_dir, zip_file)\n",
        "    extract_dir = os.path.join(download_dir, zip_file.replace('.zip', ''))\n",
        "    os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "    print(f\"Descomprimido: {zip_file} en {extract_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMwTEatUcVxX"
      },
      "outputs": [],
      "source": [
        "# Mapeo de las etiquetas a las nuevas categorías numeradas\n",
        "label_mapping = {\n",
        "    'angry': 0,        # angry -> 0\n",
        "    'neutral': 1,      # neutral -> 1\n",
        "    'disgust': 2,      # disgust -> 2\n",
        "    'fear': 3,         # fear -> 3\n",
        "    'happy': 4,        # happy -> 4\n",
        "    'sad': 5,          # sad -> 5\n",
        "    'surprise': 6,     # surprise -> 6\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFtL9j7Uf90d"
      },
      "outputs": [],
      "source": [
        "# Función para cargar imágenes y etiquetarlas\n",
        "def load_images_and_labels(dataset_path, label_mapping):\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "\n",
        "    # Recorrer las carpetas dentro del dataset\n",
        "    for class_folder in os.listdir(dataset_path):\n",
        "        class_path = os.path.join(dataset_path, class_folder)\n",
        "\n",
        "\n",
        "        if os.path.isdir(class_path):\n",
        "\n",
        "            normalized_class_folder = class_folder.lower()\n",
        "\n",
        "\n",
        "            if normalized_class_folder in ['angry', 'anger']:\n",
        "                mapped_label = label_mapping['angry']\n",
        "            elif normalized_class_folder in ['sad', 'sadness']:\n",
        "                mapped_label = label_mapping['sad']\n",
        "            elif normalized_class_folder in ['happy', 'happiness']:\n",
        "                mapped_label = label_mapping['happy']\n",
        "            elif normalized_class_folder in ['fear', 'fearful']:\n",
        "                mapped_label = label_mapping['fear']\n",
        "            elif normalized_class_folder in ['surprise', 'surprised']:\n",
        "                mapped_label = label_mapping['surprise']\n",
        "            elif normalized_class_folder in ['disgust', 'disgusted']:\n",
        "                mapped_label = label_mapping['disgust']\n",
        "            elif normalized_class_folder in ['neutrality', 'noemo']:\n",
        "                mapped_label = label_mapping['neutral']\n",
        "            elif normalized_class_folder in label_mapping:\n",
        "                mapped_label = label_mapping[normalized_class_folder]\n",
        "            else:\n",
        "                print(f\"Etiqueta no mapeada: {class_folder}\")\n",
        "                continue\n",
        "\n",
        "            for img_name in os.listdir(class_path):\n",
        "                img_path = os.path.join(class_path, img_name)\n",
        "                image_paths.append(img_path)\n",
        "                labels.append(mapped_label)\n",
        "\n",
        "    # Crear un DataFrame con las rutas de imágenes y las etiquetas mapeadas\n",
        "    df = pd.DataFrame({'image_path': image_paths, 'label': labels})\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "nkXj--eO_KcO",
        "outputId": "4ce29bbf-b2c0-4a83-b875-c47a8dbe898c"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/random-images-for-face-emotion-recognition'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-cac4ae841689>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdataset_path_11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/dataset-of-faces-as-per-emotions/Dataset_emotions'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdf_test_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_and_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mdf_test_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_and_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdf_test_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_and_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-6f0e50a5763e>\u001b[0m in \u001b[0;36mload_images_and_labels\u001b[0;34m(dataset_path, label_mapping)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Recorrer las carpetas dentro del dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mclass_folder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mclass_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/random-images-for-face-emotion-recognition'"
          ]
        }
      ],
      "source": [
        "#Lo aplicamos para los otros datasets que son compatibles con la funcion\n",
        "\n",
        "dataset_path_1 = '/content/random-images-for-face-emotion-recognition'\n",
        "dataset_path_2 = '/content/fer2013/test'\n",
        "dataset_path_3 = '/content/fer2013/train'\n",
        "dataset_path_4 = '/content/human-face-emotions/data'\n",
        "dataset_path_5 = '/content/emotion-detection-fer/test'\n",
        "dataset_path_6 = '/content/emotion-detection-fer/train'\n",
        "dataset_path_7 = '/content/facial-emotion-expressions/images/train'\n",
        "dataset_path_8 = '/content/facial-emotion-expressions/images/validation'\n",
        "dataset_path_9 = '/content/face-emotion-dataset/test'\n",
        "dataset_path_10 = '/content/face-emotion-dataset/train'\n",
        "dataset_path_11 = '/content/dataset-of-faces-as-per-emotions/Dataset_emotions'\n",
        "\n",
        "df_test_1 = load_images_and_labels(dataset_path_1, label_mapping)\n",
        "df_test_2 = load_images_and_labels(dataset_path_2, label_mapping)\n",
        "df_test_3 = load_images_and_labels(dataset_path_3, label_mapping)\n",
        "df_test_4 = load_images_and_labels(dataset_path_4, label_mapping)\n",
        "df_test_5 = load_images_and_labels(dataset_path_5, label_mapping)\n",
        "df_test_6 = load_images_and_labels(dataset_path_6, label_mapping)\n",
        "df_test_7 = load_images_and_labels(dataset_path_7, label_mapping)\n",
        "df_test_8 = load_images_and_labels(dataset_path_8, label_mapping)\n",
        "df_test_9 = load_images_and_labels(dataset_path_9, label_mapping)\n",
        "df_test_10 = load_images_and_labels(dataset_path_10, label_mapping)\n",
        "df_test_11 = load_images_and_labels(dataset_path_11, label_mapping)\n",
        "\n",
        "# Verificar la distribución de las etiquetas\n",
        "print(df_test_1['label'].value_counts())\n",
        "print(df_test_2['label'].value_counts())\n",
        "print(df_test_3['label'].value_counts())\n",
        "print(df_test_4['label'].value_counts())\n",
        "print(df_test_5['label'].value_counts())\n",
        "print(df_test_6['label'].value_counts())\n",
        "print(df_test_7['label'].value_counts())\n",
        "print(df_test_8['label'].value_counts())\n",
        "print(df_test_9['label'].value_counts())\n",
        "print(df_test_10['label'].value_counts())\n",
        "print(df_test_11['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYbCEV8l1CFt"
      },
      "outputs": [],
      "source": [
        "# Diccionario de correcciones para los nombres de las imágenes\n",
        "corrections = {\n",
        "    'surprised': 'surprise',\n",
        "    'anger': 'angry',\n",
        "    'sadness': 'sad',\n",
        "    'happiness': 'happy',\n",
        "    'fearful': 'fear',\n",
        "    'disgusted': 'disgust',\n",
        "    'noemo': 'neutral'\n",
        "}\n",
        "\n",
        "# Función para cargar imágenes y etiquetarlas\n",
        "def load_images_and_labels_2(dataset_path, label_mapping, corrections):\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "\n",
        "\n",
        "    for subject_folder in os.listdir(dataset_path):\n",
        "        subject_path = os.path.join(dataset_path, subject_folder)\n",
        "\n",
        "\n",
        "        if os.path.isdir(subject_path):\n",
        "            for img_name in os.listdir(subject_path):\n",
        "                img_path = os.path.join(subject_path, img_name)\n",
        "\n",
        "\n",
        "                img_name_lower = img_name.lower().split('.')[0]\n",
        "\n",
        "\n",
        "                if img_name_lower in corrections:\n",
        "                    img_name_lower = corrections[img_name_lower]\n",
        "\n",
        "\n",
        "                mapped_label = label_mapping.get(img_name_lower, None)\n",
        "                if mapped_label is None:\n",
        "                    print(f\"Etiqueta no mapeada: {img_name_lower} en la carpeta {subject_folder}\")\n",
        "                    continue\n",
        "\n",
        "                image_paths.append(img_path)\n",
        "                labels.append(mapped_label)\n",
        "\n",
        "    df = pd.DataFrame({'image_path': image_paths, 'label': labels})\n",
        "    return df\n",
        "\n",
        "#para el data de facial-emotion-recognition, es necesaria otra funcion\n",
        "dataset_path_12 = '/content/facial-emotion-recognition/images'\n",
        "df_test_12 = load_images_and_labels_2(dataset_path_12, label_mapping, corrections)\n",
        "\n",
        "# Ver las primeras filas para verificar que las etiquetas fueron aplicadas correctamente\n",
        "print(df_test_12.head())\n",
        "\n",
        "# Verificar la distribución de las etiquetas\n",
        "print(df_test_12['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5Bi-ZI3m1yg"
      },
      "outputs": [],
      "source": [
        "#Ahora unimos los dataframes en uno solo\n",
        "df_combined = pd.concat([ df_test_1, df_test_2, df_test_7, df_test_8,df_test_9, df_test_10, df_test_11, df_test_12], ignore_index=True)\n",
        "\n",
        "# Ver las primeras filas del DataFrame combinado\n",
        "print(df_combined.head())\n",
        "\n",
        "\n",
        "# Verificar la distribución de las etiquetas\n",
        "print(df_combined['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5p6T512Lc51"
      },
      "outputs": [],
      "source": [
        "# Filtra las imágenes de la clase 2\n",
        "df_class_2 = df_combined[df_combined['label'] == 2]\n",
        "\n",
        "# Configura las transformaciones\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Directorio de salida para las imágenes aumentadas\n",
        "output_dir = \"augmented_class_2\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Tamaño de las imágenes (ajustar si es diferente)\n",
        "img_size = (96, 96)\n",
        "\n",
        "# Número de imágenes aumentadas por ejemplo original\n",
        "n_augmentations = 5\n",
        "\n",
        "for index, row in df_class_2.iterrows():\n",
        "    img_path = row['image_path']\n",
        "\n",
        "    # Cargar la imagen original\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        print(f\"Error al cargar la imagen: {img_path}\")\n",
        "        continue\n",
        "\n",
        "    # Redimensionar si es necesario\n",
        "    img = cv2.resize(img, img_size)\n",
        "\n",
        "    # Expandir dimensión para adaptarse a ImageDataGenerator\n",
        "    img = np.expand_dims(img, axis=-1)\n",
        "    img = np.expand_dims(img, axis=0)  # (1, img_size[0], img_size[1], 1)\n",
        "\n",
        "    # Generar imágenes aumentadas\n",
        "    i = 0\n",
        "    for batch in datagen.flow(img, batch_size=1, save_to_dir=output_dir,\n",
        "                              save_prefix='class_2', save_format='png'):\n",
        "        i += 1\n",
        "        if i >= n_augmentations:\n",
        "            break  # Limitar el número de augmentaciones por imagen\n",
        "\n",
        "print(f\"Datos aumentados guardados en: {output_dir}\")\n",
        "\n",
        "\n",
        "# Obtener los nuevos paths de las imágenes aumentadas\n",
        "augmented_images = glob.glob(os.path.join(output_dir, \"*.png\"))\n",
        "\n",
        "# Crear un nuevo dataframe para las imágenes aumentadas\n",
        "df_augmented = pd.DataFrame({\n",
        "    'image_path': augmented_images,\n",
        "    'label': 2  # Etiqueta correspondiente\n",
        "})\n",
        "\n",
        "# Concatenar con el dataset original\n",
        "df_new = pd.concat([df_combined, df_augmented], ignore_index=True)\n",
        "\n",
        "# Ver las primeras filas del nuevo DataFrame\n",
        "print(df_new.head())\n",
        "\n",
        "\n",
        "# Verificar la distribución de las etiquetas\n",
        "print(df_new['label'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hG6PfUvGdXsb"
      },
      "outputs": [],
      "source": [
        "x = df_new['label'].value_counts()\n",
        "plt.bar(x.index, x.values)\n",
        "plt.xlabel('categorias')\n",
        "plt.ylabel('numero de imagenes')\n",
        "plt.title('Distribución de las imagenes')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVXx7bPFfSkr"
      },
      "outputs": [],
      "source": [
        "num_eliminar_4 = 16000\n",
        "num_eliminar_5 = 6000\n",
        "num_eliminar_1 = 6000\n",
        "num_eliminar_0 = 3000\n",
        "num_eliminar_3 = 2000\n",
        "\n",
        "df_class_4 = df_new[df_new['label'] == 4]\n",
        "df_class_5 = df_new[df_new['label'] == 5]\n",
        "df_class_1 = df_new[df_new['label'] == 1]\n",
        "df_class_0 = df_new[df_new['label'] == 0]\n",
        "df_class_3 = df_new[df_new['label'] == 3]\n",
        "\n",
        "# Asegúrate de que num_eliminar sea menor o igual al tamaño de df_class_4\n",
        "num_eliminar_4 = min(num_eliminar_4, len(df_class_4))\n",
        "num_eliminar_5 = min(num_eliminar_5, len(df_class_5))\n",
        "num_eliminar_1 = min(num_eliminar_1, len(df_class_1))\n",
        "num_eliminar_0 = min(num_eliminar_0, len(df_class_0))\n",
        "num_eliminar_3 = min(num_eliminar_3, len(df_class_3))\n",
        "\n",
        "# Selecciona índices aleatorios para eliminar\n",
        "# Usamos .index para obtener los índices del DataFrame\n",
        "indices_eliminar = random.sample(list(df_class_4.index), num_eliminar_4) + random.sample(list(df_class_5.index), num_eliminar_5) + random.sample(list(df_class_1.index), num_eliminar_1) + random.sample(list(df_class_0.index), num_eliminar_0)+ random.sample(list(df_class_3.index), num_eliminar_3)\n",
        "\n",
        "# Elimina los índices seleccionados de df_combined (no de df, que no está definido)\n",
        "df_filtrado = df_new.drop(indices_eliminar)\n",
        "\n",
        "\n",
        "# Verificar la distribución de las etiquetas\n",
        "print(df_filtrado['label'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Asb1Wwawg9XC"
      },
      "outputs": [],
      "source": [
        "x = df_filtrado['label'].value_counts()\n",
        "plt.bar(x.index, x.values)\n",
        "plt.xlabel('categorias')\n",
        "plt.ylabel('numero de imagenes')\n",
        "plt.title('Distribución de las imagenes')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSsFDE5Dxjw_"
      },
      "outputs": [],
      "source": [
        "# Verificar si las rutas de las imágenes son correctas\n",
        "for index, row in df_filtrado.iterrows():\n",
        "    if not os.path.exists(row['image_path']):\n",
        "        print(f\"¡Ruta no válida! {row['image_path']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7yz_JllyEXk"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_images(df, img_size=(48, 48)):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "\n",
        "        if not os.path.exists(row['image_path']):\n",
        "            print(f\"Imagen no encontrada: {row['image_path']}\")\n",
        "            continue\n",
        "\n",
        "\n",
        "        img = cv2.imread(row['image_path'])\n",
        "\n",
        "        if img is None:\n",
        "            print(f\"Error al cargar la imagen: {row['image_path']}\")\n",
        "            continue\n",
        "\n",
        "        # Convertir la imagen a escala de grises y redimensionar\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        img = cv2.resize(img, img_size)\n",
        "\n",
        "        # Normalizar la imagen\n",
        "        img = img / 255.0\n",
        "\n",
        "        images.append(img)\n",
        "        labels.append(row['label'])\n",
        "\n",
        "    # Convertir a arrays de numpy\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # Expande las dimensiones para la compatibilidad con CNN\n",
        "    images = images.reshape(-1, img_size[0], img_size[1], 1)\n",
        "\n",
        "    return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U54u4Gtk3nXV"
      },
      "outputs": [],
      "source": [
        "# Dividir en entrenamiento (60%), validación (20%) y prueba (20%)\n",
        "images, labels = load_and_preprocess_images(df_filtrado)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Entrenamiento: {len(X_train)} muestras\")\n",
        "print(f\"Validación: {len(X_val)} muestras\")\n",
        "print(f\"Prueba: {len(X_test)} muestras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6bIbWt0yw8J"
      },
      "outputs": [],
      "source": [
        "# Crear el modelo CNN\n",
        "model = models.Sequential([\n",
        "\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', padding = 'same', input_shape=(48, 48, 1)),# Primer capa convolucional\n",
        "    LeakyReLU(alpha=0.1),      # LeakyReLU\n",
        "    BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),  # Capa de max pooling\n",
        "    Dropout(0.25),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding = 'same'),  # Segunda capa convolucional\n",
        "    LeakyReLU(alpha=0.1),      # LeakyReLU\n",
        "    BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),  # Capa de max pooling\n",
        "    Dropout(0.33),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding = 'same'),  # Tercera capa convolucional\n",
        "    LeakyReLU(alpha=0.1),      # LeakyReLU\n",
        "    BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),  # Capa de max pooling\n",
        "\n",
        "    layers.Conv2D(256, (3, 3), activation='relu', padding = 'same'),  # Tercera capa convolucional\n",
        "    LeakyReLU(alpha=0.1),      # LeakyReLU\n",
        "    BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),  # Capa de max pooling\n",
        "\n",
        "\n",
        "    layers.Flatten(),  # Aplanar la salida para la capa densa\n",
        "    Dropout(0.5),\n",
        "\n",
        "    layers.Dense(200, activation='relu', kernel_regularizer=regularizers.l2(0.02)),  #Primera Capa densa\n",
        "    BatchNormalization(),\n",
        "\n",
        "    layers.Dense(170, activation='relu', kernel_regularizer=regularizers.l2(0.02)),  #Primera Capa densa\n",
        "    BatchNormalization(),\n",
        "\n",
        "    layers.Dense(100, activation='relu', kernel_regularizer=regularizers.l2(0.02)),  #Primera Capa densa\n",
        "    BatchNormalization(),\n",
        "\n",
        "    layers.Dense(7, activation='softmax')  # Capa de salida (7 clases)\n",
        "])\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',  # Usamos esta función ya que las etiquetas son números enteros\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Resumen del modelo\n",
        "model.summary()\n",
        "\n",
        "# Entrenar el modelo\n",
        "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_val, y_val))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhpIWjqv0XP7"
      },
      "outputs": [],
      "source": [
        "# Graficar la precisión durante el entrenamiento\n",
        "plt.plot(history.history['accuracy'], label='Precisión en entrenamiento')\n",
        "plt.plot(history.history['val_accuracy'], label='Precisión en validación')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Precisión')\n",
        "plt.legend()\n",
        "plt.title('Precisión durante el entrenamiento')\n",
        "plt.show()\n",
        "\n",
        "# Graficar la pérdida durante el entrenamiento\n",
        "plt.plot(history.history['loss'], label='Pérdida en entrenamiento')\n",
        "plt.plot(history.history['val_loss'], label='Pérdida en validación')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.legend()\n",
        "plt.title('Pérdida durante el entrenamiento')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yk29dFHXMCHE"
      },
      "outputs": [],
      "source": [
        "# Predicciones del modelo\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Convertir las probabilidades a clases (índice con la mayor probabilidad)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "\n",
        "# Crear la matriz de confusión\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "print(\"Matriz de confusión:\")\n",
        "print(conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFmnm5JZJWgr"
      },
      "outputs": [],
      "source": [
        "# Etiquetas de las clases\n",
        "class_names = ['Angry', 'Neutral', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise']\n",
        "\n",
        "# Graficar la matriz de confusión\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Etiqueta Real')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vH0KnPLFJhcd"
      },
      "outputs": [],
      "source": [
        "# Reporte completo de clasificación\n",
        "print(classification_report(y_test, y_pred_classes, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PPpyYYLH3SV"
      },
      "outputs": [],
      "source": [
        "# Guardar el modelo entrenado\n",
        "model.save('Clasificador_emociones.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpMNJTtXg65I"
      },
      "outputs": [],
      "source": [
        "# Guardar el modelo en formato Keras\n",
        "model.save('/content/Clasificador_emociones.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zx76h0oLg4IJ"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_val)\n",
        "y_pred_classes = np.argmax(y_pred,axis=1)\n",
        "class_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']\n",
        "# Reporte completo de clasificación\n",
        "print(classification_report(y_val, y_pred_classes, target_names=class_names))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
