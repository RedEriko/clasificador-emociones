{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTql6lj1lAiD",
        "outputId": "29b505e3-3304-45c4-abb6-8612aa156961"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "mv: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# Instalaci√≥n de bibliotecas\n",
        "!pip install tensorflow pandas matplotlib opencv-python scikit-learn\n",
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.layers import LeakyReLU, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/root/.kaggle\"\n",
        "!mkdir -p /root/.kaggle\n",
        "!mv kaggle.json /root/.kaggle/\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw-2kUeKmyw8",
        "outputId": "a675a3e8-ca96-4e57-d82c-5ae2294fc005"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/msambare/fer2013\n",
            "License(s): DbCL-1.0\n",
            "Downloading fer2013.zip to /content\n",
            " 75% 45.0M/60.3M [00:00<00:00, 98.4MB/s]\n",
            "100% 60.3M/60.3M [00:00<00:00, 114MB/s] \n",
            "403 - Forbidden - Permission 'datasets.get' was denied\n",
            "Dataset URL: https://www.kaggle.com/datasets/ananthu017/emotion-detection-fer\n",
            "License(s): CC0-1.0\n",
            "Downloading emotion-detection-fer.zip to /content\n",
            " 89% 58.0M/65.2M [00:00<00:00, 76.7MB/s]\n",
            "100% 65.2M/65.2M [00:01<00:00, 67.6MB/s]\n",
            "403 - Forbidden - Permission 'datasets.get' was denied\n",
            "Dataset URL: https://www.kaggle.com/datasets/missaouimohamedamine/face-emotion-dataset\n",
            "License(s): apache-2.0\n",
            "Downloading face-emotion-dataset.zip to /content\n",
            "100% 123M/123M [00:02<00:00, 77.1MB/s]\n",
            "100% 123M/123M [00:02<00:00, 60.1MB/s]\n",
            "Dataset URL: https://www.kaggle.com/datasets/tonny22/dataset-of-faces-as-per-emotions\n",
            "License(s): unknown\n",
            "Downloading dataset-of-faces-as-per-emotions.zip to /content\n",
            "100% 462M/464M [00:07<00:00, 81.2MB/s]\n",
            "100% 464M/464M [00:07<00:00, 67.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d msambare/fer2013\n",
        "!kaggle datasets download -d tapakah68/facial-emotion-recognitio\n",
        "!kaggle datasets download -d ananthu017/emotion-detection-fer\n",
        "!kaggle datasets download -d samaneheslamifar/facial-emotion-expression\n",
        "!kaggle datasets download -d missaouimohamedamine/face-emotion-dataset\n",
        "!kaggle datasets download -d tonny22/dataset-of-faces-as-per-emotions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwsIybjlnuZi",
        "outputId": "88adb6c4-2682-4ec9-fb00-d97b46c6ef1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Descomprimido: emotion-detection-fer.zip en /content/emotion-detection-fer\n",
            "Descomprimido: fer2013.zip en /content/fer2013\n",
            "Descomprimido: dataset-of-faces-as-per-emotions.zip en /content/dataset-of-faces-as-per-emotions\n",
            "Descomprimido: face-emotion-dataset.zip en /content/face-emotion-dataset\n"
          ]
        }
      ],
      "source": [
        "# Directorio donde est√°n los archivos .zip descargados\n",
        "download_dir = '/content/'\n",
        "\n",
        "# Listamos todos los archivos en el directorio\n",
        "zip_files = [f for f in os.listdir(download_dir) if f.endswith('.zip')]\n",
        "\n",
        "# Descomprimir todos los archivos .zip\n",
        "for zip_file in zip_files:\n",
        "    zip_path = os.path.join(download_dir, zip_file)\n",
        "    extract_dir = os.path.join(download_dir, zip_file.replace('.zip', ''))\n",
        "    os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "    print(f\"Descomprimido: {zip_file} en {extract_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMwTEatUcVxX"
      },
      "outputs": [],
      "source": [
        "# Mapeo de las etiquetas a las nuevas categor√≠as numeradas\n",
        "label_mapping = {\n",
        "    'angry': 0,        # angry -> 0\n",
        "    'neutral': 1,      # neutral -> 1\n",
        "    'disgust': 2,      # disgust -> 2\n",
        "    'fear': 3,         # fear -> 3\n",
        "    'happy': 4,        # happy -> 4\n",
        "    'sad': 5,          # sad -> 5\n",
        "    'surprise': 6,     # surprise -> 6\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFtL9j7Uf90d"
      },
      "outputs": [],
      "source": [
        "# Funci√≥n para cargar im√°genes y etiquetarlas\n",
        "def load_images_and_labels(dataset_path, label_mapping):\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "\n",
        "    # Recorrer las carpetas dentro del dataset\n",
        "    for class_folder in os.listdir(dataset_path):\n",
        "        class_path = os.path.join(dataset_path, class_folder)\n",
        "\n",
        "\n",
        "        if os.path.isdir(class_path):\n",
        "\n",
        "            normalized_class_folder = class_folder.lower()\n",
        "\n",
        "\n",
        "            if normalized_class_folder in ['angry', 'anger']:\n",
        "                mapped_label = label_mapping['angry']\n",
        "            elif normalized_class_folder in ['sad', 'sadness']:\n",
        "                mapped_label = label_mapping['sad']\n",
        "            elif normalized_class_folder in ['happy', 'happiness']:\n",
        "                mapped_label = label_mapping['happy']\n",
        "            elif normalized_class_folder in ['fear', 'fearful']:\n",
        "                mapped_label = label_mapping['fear']\n",
        "            elif normalized_class_folder in ['surprise', 'surprised']:\n",
        "                mapped_label = label_mapping['surprise']\n",
        "            elif normalized_class_folder in ['disgust', 'disgusted']:\n",
        "                mapped_label = label_mapping['disgust']\n",
        "            elif normalized_class_folder in ['neutrality', 'noemo']:\n",
        "                mapped_label = label_mapping['neutral']\n",
        "            elif normalized_class_folder in label_mapping:\n",
        "                mapped_label = label_mapping[normalized_class_folder]\n",
        "            else:\n",
        "                print(f\"Etiqueta no mapeada: {class_folder}\")\n",
        "                continue\n",
        "\n",
        "            for img_name in os.listdir(class_path):\n",
        "                img_path = os.path.join(class_path, img_name)\n",
        "                image_paths.append(img_path)\n",
        "                labels.append(mapped_label)\n",
        "\n",
        "    # Crear un DataFrame con las rutas de im√°genes y las etiquetas mapeadas\n",
        "    df = pd.DataFrame({'image_path': image_paths, 'label': labels})\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "nkXj--eO_KcO",
        "outputId": "4ce29bbf-b2c0-4a83-b875-c47a8dbe898c"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/random-images-for-face-emotion-recognition'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-cac4ae841689>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdataset_path_11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/dataset-of-faces-as-per-emotions/Dataset_emotions'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdf_test_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_and_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mdf_test_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_and_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdf_test_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_and_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-6f0e50a5763e>\u001b[0m in \u001b[0;36mload_images_and_labels\u001b[0;34m(dataset_path, label_mapping)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Recorrer las carpetas dentro del dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mclass_folder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mclass_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/random-images-for-face-emotion-recognition'"
          ]
        }
      ],
      "source": [
        "#Lo aplicamos para los otros datasets que son compatibles con la funcion\n",
        "\n",
        "dataset_path_1 = '/content/random-images-for-face-emotion-recognition'\n",
        "dataset_path_2 = '/content/fer2013/test'\n",
        "dataset_path_3 = '/content/fer2013/train'\n",
        "dataset_path_4 = '/content/human-face-emotions/data'\n",
        "dataset_path_5 = '/content/emotion-detection-fer/test'\n",
        "dataset_path_6 = '/content/emotion-detection-fer/train'\n",
        "dataset_path_7 = '/content/facial-emotion-expressions/images/train'\n",
        "dataset_path_8 = '/content/facial-emotion-expressions/images/validation'\n",
        "dataset_path_9 = '/content/face-emotion-dataset/test'\n",
        "dataset_path_10 = '/content/face-emotion-dataset/train'\n",
        "dataset_path_11 = '/content/dataset-of-faces-as-per-emotions/Dataset_emotions'\n",
        "\n",
        "df_test_1 = load_images_and_labels(dataset_path_1, label_mapping)\n",
        "df_test_2 = load_images_and_labels(dataset_path_2, label_mapping)\n",
        "df_test_3 = load_images_and_labels(dataset_path_3, label_mapping)\n",
        "df_test_4 = load_images_and_labels(dataset_path_4, label_mapping)\n",
        "df_test_5 = load_images_and_labels(dataset_path_5, label_mapping)\n",
        "df_test_6 = load_images_and_labels(dataset_path_6, label_mapping)\n",
        "df_test_7 = load_images_and_labels(dataset_path_7, label_mapping)\n",
        "df_test_8 = load_images_and_labels(dataset_path_8, label_mapping)\n",
        "df_test_9 = load_images_and_labels(dataset_path_9, label_mapping)\n",
        "df_test_10 = load_images_and_labels(dataset_path_10, label_mapping)\n",
        "df_test_11 = load_images_and_labels(dataset_path_11, label_mapping)\n",
        "\n",
        "# Verificar la distribuci√≥n de las etiquetas\n",
        "print(df_test_1['label'].value_counts())\n",
        "print(df_test_2['label'].value_counts())\n",
        "print(df_test_3['label'].value_counts())\n",
        "print(df_test_4['label'].value_counts())\n",
        "print(df_test_5['label'].value_counts())\n",
        "print(df_test_6['label'].value_counts())\n",
        "print(df_test_7['label'].value_counts())\n",
        "print(df_test_8['label'].value_counts())\n",
        "print(df_test_9['label'].value_counts())\n",
        "print(df_test_10['label'].value_counts())\n",
        "print(df_test_11['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYbCEV8l1CFt"
      },
      "outputs": [],
      "source": [
        "# Diccionario de correcciones para los nombres de las im√°genes\n",
        "corrections = {\n",
        "    'surprised': 'surprise',\n",
        "    'anger': 'angry',\n",
        "    'sadness': 'sad',\n",
        "    'happiness': 'happy',\n",
        "    'fearful': 'fear',\n",
        "    'disgusted': 'disgust',\n",
        "    'noemo': 'neutral'\n",
        "}\n",
        "\n",
        "# Funci√≥n para cargar im√°genes y etiquetarlas\n",
        "def load_images_and_labels_2(dataset_path, label_mapping, corrections):\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "\n",
        "\n",
        "    for subject_folder in os.listdir(dataset_path):\n",
        "        subject_path = os.path.join(dataset_path, subject_folder)\n",
        "\n",
        "\n",
        "        if os.path.isdir(subject_path):\n",
        "            for img_name in os.listdir(subject_path):\n",
        "                img_path = os.path.join(subject_path, img_name)\n",
        "\n",
        "\n",
        "                img_name_lower = img_name.lower().split('.')[0]\n",
        "\n",
        "\n",
        "                if img_name_lower in corrections:\n",
        "                    img_name_lower = corrections[img_name_lower]\n",
        "\n",
        "\n",
        "                mapped_label = label_mapping.get(img_name_lower, None)\n",
        "                if mapped_label is None:\n",
        "                    print(f\"Etiqueta no mapeada: {img_name_lower} en la carpeta {subject_folder}\")\n",
        "                    continue\n",
        "\n",
        "                image_paths.append(img_path)\n",
        "                labels.append(mapped_label)\n",
        "\n",
        "    df = pd.DataFrame({'image_path': image_paths, 'label': labels})\n",
        "    return df\n",
        "\n",
        "#para el data de facial-emotion-recognition, es necesaria otra funcion\n",
        "dataset_path_12 = '/content/facial-emotion-recognition/images'\n",
        "df_test_12 = load_images_and_labels_2(dataset_path_12, label_mapping, corrections)\n",
        "\n",
        "# Ver las primeras filas para verificar que las etiquetas fueron aplicadas correctamente\n",
        "print(df_test_12.head())\n",
        "\n",
        "# Verificar la distribuci√≥n de las etiquetas\n",
        "print(df_test_12['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5Bi-ZI3m1yg"
      },
      "outputs": [],
      "source": [
        "#Ahora unimos los dataframes en uno solo\n",
        "df_combined = pd.concat([ df_test_1, df_test_2, df_test_7, df_test_8,df_test_9, df_test_10, df_test_11, df_test_12], ignore_index=True)\n",
        "\n",
        "# Ver las primeras filas del DataFrame combinado\n",
        "print(df_combined.head())\n",
        "\n",
        "\n",
        "# Verificar la distribuci√≥n de las etiquetas\n",
        "print(df_combined['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5p6T512Lc51"
      },
      "outputs": [],
      "source": [
        "# Filtra las im√°genes de la clase 2\n",
        "df_class_2 = df_combined[df_combined['label'] == 2]\n",
        "\n",
        "# Configura las transformaciones\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Directorio de salida para las im√°genes aumentadas\n",
        "output_dir = \"augmented_class_2\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Tama√±o de las im√°genes (ajustar si es diferente)\n",
        "img_size = (96, 96)\n",
        "\n",
        "# N√∫mero de im√°genes aumentadas por ejemplo original\n",
        "n_augmentations = 5\n",
        "\n",
        "for index, row in df_class_2.iterrows():\n",
        "    img_path = row['image_path']\n",
        "\n",
        "    # Cargar la imagen original\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        print(f\"Error al cargar la imagen: {img_path}\")\n",
        "        continue\n",
        "\n",
        "    # Redimensionar si es necesario\n",
        "    img = cv2.resize(img, img_size)\n",
        "\n",
        "    # Expandir dimensi√≥n para adaptarse a ImageDataGenerator\n",
        "    img = np.expand_dims(img, axis=-1)\n",
        "    img = np.expand_dims(img, axis=0)  # (1, img_size[0], img_size[1], 1)\n",
        "\n",
        "    # Generar im√°genes aumentadas\n",
        "    i = 0\n",
        "    for batch in datagen.flow(img, batch_size=1, save_to_dir=output_dir,\n",
        "                              save_prefix='class_2', save_format='png'):\n",
        "        i += 1\n",
        "        if i >= n_augmentations:\n",
        "            break  # Limitar el n√∫mero de augmentaciones por imagen\n",
        "\n",
        "print(f\"Datos aumentados guardados en: {output_dir}\")\n",
        "\n",
        "\n",
        "# Obtener los nuevos paths de las im√°genes aumentadas\n",
        "augmented_images = glob.glob(os.path.join(output_dir, \"*.png\"))\n",
        "\n",
        "# Crear un nuevo dataframe para las im√°genes aumentadas\n",
        "df_augmented = pd.DataFrame({\n",
        "    'image_path': augmented_images,\n",
        "    'label': 2  # Etiqueta correspondiente\n",
        "})\n",
        "\n",
        "# Concatenar con el dataset original\n",
        "df_new = pd.concat([df_combined, df_augmented], ignore_index=True)\n",
        "\n",
        "# Ver las primeras filas del nuevo DataFrame\n",
        "print(df_new.head())\n",
        "\n",
        "\n",
        "# Verificar la distribuci√≥n de las etiquetas\n",
        "print(df_new['label'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hG6PfUvGdXsb"
      },
      "outputs": [],
      "source": [
        "x = df_new['label'].value_counts()\n",
        "plt.bar(x.index, x.values)\n",
        "plt.xlabel('categorias')\n",
        "plt.ylabel('numero de imagenes')\n",
        "plt.title('Distribuci√≥n de las imagenes')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVXx7bPFfSkr"
      },
      "outputs": [],
      "source": [
        "num_eliminar_4 = 16000\n",
        "num_eliminar_5 = 6000\n",
        "num_eliminar_1 = 6000\n",
        "num_eliminar_0 = 3000\n",
        "num_eliminar_3 = 2000\n",
        "\n",
        "df_class_4 = df_new[df_new['label'] == 4]\n",
        "df_class_5 = df_new[df_new['label'] == 5]\n",
        "df_class_1 = df_new[df_new['label'] == 1]\n",
        "df_class_0 = df_new[df_new['label'] == 0]\n",
        "df_class_3 = df_new[df_new['label'] == 3]\n",
        "\n",
        "# Aseg√∫rate de que num_eliminar sea menor o igual al tama√±o de df_class_4\n",
        "num_eliminar_4 = min(num_eliminar_4, len(df_class_4))\n",
        "num_eliminar_5 = min(num_eliminar_5, len(df_class_5))\n",
        "num_eliminar_1 = min(num_eliminar_1, len(df_class_1))\n",
        "num_eliminar_0 = min(num_eliminar_0, len(df_class_0))\n",
        "num_eliminar_3 = min(num_eliminar_3, len(df_class_3))\n",
        "\n",
        "# Selecciona √≠ndices aleatorios para eliminar\n",
        "# Usamos .index para obtener los √≠ndices del DataFrame\n",
        "indices_eliminar = random.sample(list(df_class_4.index), num_eliminar_4) + random.sample(list(df_class_5.index), num_eliminar_5) + random.sample(list(df_class_1.index), num_eliminar_1) + random.sample(list(df_class_0.index), num_eliminar_0)+ random.sample(list(df_class_3.index), num_eliminar_3)\n",
        "\n",
        "# Elimina los √≠ndices seleccionados de df_combined (no de df, que no est√° definido)\n",
        "df_filtrado = df_new.drop(indices_eliminar)\n",
        "\n",
        "\n",
        "# Verificar la distribuci√≥n de las etiquetas\n",
        "print(df_filtrado['label'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Asb1Wwawg9XC"
      },
      "outputs": [],
      "source": [
        "x = df_filtrado['label'].value_counts()\n",
        "plt.bar(x.index, x.values)\n",
        "plt.xlabel('categorias')\n",
        "plt.ylabel('numero de imagenes')\n",
        "plt.title('Distribuci√≥n de las imagenes')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSsFDE5Dxjw_"
      },
      "outputs": [],
      "source": [
        "# Verificar si las rutas de las im√°genes son correctas\n",
        "for index, row in df_filtrado.iterrows():\n",
        "    if not os.path.exists(row['image_path']):\n",
        "        print(f\"¬°Ruta no v√°lida! {row['image_path']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7yz_JllyEXk"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_images(df, img_size=(48, 48)):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "\n",
        "        if not os.path.exists(row['image_path']):\n",
        "            print(f\"Imagen no encontrada: {row['image_path']}\")\n",
        "            continue\n",
        "\n",
        "\n",
        "        img = cv2.imread(row['image_path'])\n",
        "\n",
        "        if img is None:\n",
        "            print(f\"Error al cargar la imagen: {row['image_path']}\")\n",
        "            continue\n",
        "\n",
        "        # Convertir la imagen a escala de grises y redimensionar\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        img = cv2.resize(img, img_size)\n",
        "\n",
        "        # Normalizar la imagen\n",
        "        img = img / 255.0\n",
        "\n",
        "        images.append(img)\n",
        "        labels.append(row['label'])\n",
        "\n",
        "    # Convertir a arrays de numpy\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # Expande las dimensiones para la compatibilidad con CNN\n",
        "    images = images.reshape(-1, img_size[0], img_size[1], 1)\n",
        "\n",
        "    return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U54u4Gtk3nXV"
      },
      "outputs": [],
      "source": [
        "# Dividir en entrenamiento (60%), validaci√≥n (20%) y prueba (20%)\n",
        "images, labels = load_and_preprocess_images(df_filtrado)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Entrenamiento: {len(X_train)} muestras\")\n",
        "print(f\"Validaci√≥n: {len(X_val)} muestras\")\n",
        "print(f\"Prueba: {len(X_test)} muestras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6bIbWt0yw8J"
      },
      "outputs": [],
      "source": [
        "# Crear el modelo CNN\n",
        "model = models.Sequential([\n",
        "\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', padding = 'same', input_shape=(48, 48, 1)),# Primer capa convolucional\n",
        "    LeakyReLU(alpha=0.1),      # LeakyReLU\n",
        "    BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),  # Capa de max pooling\n",
        "    Dropout(0.25),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding = 'same'),  # Segunda capa convolucional\n",
        "    LeakyReLU(alpha=0.1),      # LeakyReLU\n",
        "    BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),  # Capa de max pooling\n",
        "    Dropout(0.33),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding = 'same'),  # Tercera capa convolucional\n",
        "    LeakyReLU(alpha=0.1),      # LeakyReLU\n",
        "    BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),  # Capa de max pooling\n",
        "\n",
        "    layers.Conv2D(256, (3, 3), activation='relu', padding = 'same'),  # Tercera capa convolucional\n",
        "    LeakyReLU(alpha=0.1),      # LeakyReLU\n",
        "    BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),  # Capa de max pooling\n",
        "\n",
        "\n",
        "    layers.Flatten(),  # Aplanar la salida para la capa densa\n",
        "    Dropout(0.5),\n",
        "\n",
        "    layers.Dense(200, activation='relu', kernel_regularizer=regularizers.l2(0.02)),  #Primera Capa densa\n",
        "    BatchNormalization(),\n",
        "\n",
        "    layers.Dense(170, activation='relu', kernel_regularizer=regularizers.l2(0.02)),  #Primera Capa densa\n",
        "    BatchNormalization(),\n",
        "\n",
        "    layers.Dense(100, activation='relu', kernel_regularizer=regularizers.l2(0.02)),  #Primera Capa densa\n",
        "    BatchNormalization(),\n",
        "\n",
        "    layers.Dense(7, activation='softmax')  # Capa de salida (7 clases)\n",
        "])\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',  # Usamos esta funci√≥n ya que las etiquetas son n√∫meros enteros\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Resumen del modelo\n",
        "model.summary()\n",
        "\n",
        "# Entrenar el modelo\n",
        "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_val, y_val))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhpIWjqv0XP7"
      },
      "outputs": [],
      "source": [
        "# Graficar la precisi√≥n durante el entrenamiento\n",
        "plt.plot(history.history['accuracy'], label='Precisi√≥n en entrenamiento')\n",
        "plt.plot(history.history['val_accuracy'], label='Precisi√≥n en validaci√≥n')\n",
        "plt.xlabel('√âpocas')\n",
        "plt.ylabel('Precisi√≥n')\n",
        "plt.legend()\n",
        "plt.title('Precisi√≥n durante el entrenamiento')\n",
        "plt.show()\n",
        "\n",
        "# Graficar la p√©rdida durante el entrenamiento\n",
        "plt.plot(history.history['loss'], label='P√©rdida en entrenamiento')\n",
        "plt.plot(history.history['val_loss'], label='P√©rdida en validaci√≥n')\n",
        "plt.xlabel('√âpocas')\n",
        "plt.ylabel('P√©rdida')\n",
        "plt.legend()\n",
        "plt.title('P√©rdida durante el entrenamiento')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yk29dFHXMCHE"
      },
      "outputs": [],
      "source": [
        "# Predicciones del modelo\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Convertir las probabilidades a clases (√≠ndice con la mayor probabilidad)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "\n",
        "# Crear la matriz de confusi√≥n\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "print(\"Matriz de confusi√≥n:\")\n",
        "print(conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFmnm5JZJWgr"
      },
      "outputs": [],
      "source": [
        "# Etiquetas de las clases\n",
        "class_names = ['Angry', 'Neutral', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise']\n",
        "\n",
        "# Graficar la matriz de confusi√≥n\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Matriz de Confusi√≥n')\n",
        "plt.xlabel('Predicci√≥n')\n",
        "plt.ylabel('Etiqueta Real')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vH0KnPLFJhcd"
      },
      "outputs": [],
      "source": [
        "# Reporte completo de clasificaci√≥n\n",
        "print(classification_report(y_test, y_pred_classes, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PPpyYYLH3SV"
      },
      "outputs": [],
      "source": [
        "# Guardar el modelo entrenado\n",
        "model.save('Clasificador_emociones.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpMNJTtXg65I"
      },
      "outputs": [],
      "source": [
        "# Guardar el modelo en formato Keras\n",
        "model.save('/content/Clasificador_emociones.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zx76h0oLg4IJ"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_val)\n",
        "y_pred_classes = np.argmax(y_pred,axis=1)\n",
        "class_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']\n",
        "# Reporte completo de clasificaci√≥n\n",
        "print(classification_report(y_val, y_pred_classes, target_names=class_names))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
